
<!DOCTYPE html>
<html>
<head>
<APM_DO_NOT_TOUCH>

<script type="text/javascript">
(function(){
window.WwiL=!!window.WwiL;try{(function(){(function(){var a=-1;a={A:++a,dc:"false"[a],a:++a,Ja:"false"[a],K:++a,Ze:"[object Object]"[a],eb:(a[a]+"")[a],Ka:++a,cb:"true"[a],D:++a,M:++a,ec:"[object Object]"[a],o:++a,U:++a,qj:++a,pj:++a};try{a.Ia=(a.Ia=a+"")[a.M]+(a.xa=a.Ia[a.a])+(a.cc=(a.wa+"")[a.a])+(!a+"")[a.Ka]+(a.ya=a.Ia[a.o])+(a.wa="true"[a.a])+(a.gb="true"[a.K])+a.Ia[a.M]+a.ya+a.xa+a.wa,a.cc=a.wa+"true"[a.Ka]+a.ya+a.gb+a.wa+a.cc,a.wa=a.A[a.Ia][a.Ia],a.wa(a.wa(a.cc+'"\\'+a.a+a.M+a.a+a.dc+"\\"+a.D+a.A+"("+a.ya+"\\"+a.a+a.U+a.a+"\\"+a.a+
a.o+a.A+a.cb+a.xa+a.dc+"\\"+a.D+a.A+"\\"+a.a+a.o+a.U+"\\"+a.a+a.M+a.a+"\\"+a.a+a.M+a.o+a.eb+a.xa+"\\"+a.a+a.o+a.U+"['\\"+a.a+a.o+a.A+a.Ja+"\\"+a.a+a.U+a.a+"false"[a.K]+a.xa+a.Ja+a.eb+"']\\"+a.D+a.A+"===\\"+a.D+a.A+"'\\"+a.a+a.o+a.Ka+a.ya+"\\"+a.a+a.o+a.K+"\\"+a.a+a.M+a.a+"\\"+a.a+a.M+a.o+"\\"+a.a+a.D+a.U+"')\\"+a.D+a.A+"{\\"+a.a+a.K+"\\"+a.a+a.a+"\\"+a.a+a.o+a.o+a.Ja+"\\"+a.a+a.o+a.K+"\\"+a.D+a.A+a.cb+a.eb+"\\"+a.a+a.o+a.o+a.ec+"\\"+a.a+a.U+a.a+a.gb+"\\"+a.a+a.M+a.K+"\\"+a.a+a.M+a.Ka+"\\"+a.a+a.o+
a.A+"\\"+a.D+a.A+"=\\"+a.D+a.A+"\\"+a.a+a.o+a.U+"\\"+a.a+a.M+a.a+"\\"+a.a+a.M+a.o+a.eb+a.xa+"\\"+a.a+a.o+a.U+"['\\"+a.a+a.o+a.A+a.Ja+"\\"+a.a+a.U+a.a+"false"[a.K]+a.xa+a.Ja+a.eb+"'].\\"+a.a+a.o+a.K+a.cb+"\\"+a.a+a.o+a.A+"false"[a.K]+a.Ja+a.ec+a.cb+"(/.{"+a.a+","+a.D+"}/\\"+a.a+a.D+a.U+",\\"+a.D+a.A+a.dc+a.gb+"\\"+a.a+a.M+a.o+a.ec+a.ya+"\\"+a.a+a.M+a.a+a.xa+"\\"+a.a+a.M+a.o+"\\"+a.D+a.A+"(\\"+a.a+a.U+a.A+")\\"+a.D+a.A+"{\\"+a.a+a.K+"\\"+a.a+a.a+"\\"+a.a+a.a+"\\"+a.a+a.a+"\\"+a.a+a.o+a.K+a.cb+a.ya+
a.gb+"\\"+a.a+a.o+a.K+"\\"+a.a+a.M+a.o+"\\"+a.D+a.A+"(\\"+a.a+a.U+a.A+"\\"+a.D+a.A+"+\\"+a.D+a.A+"\\"+a.a+a.U+a.A+").\\"+a.a+a.o+a.Ka+a.gb+a.Ze+"\\"+a.a+a.o+a.Ka+a.ya+"\\"+a.a+a.o+a.K+"("+a.K+",\\"+a.D+a.A+a.D+")\\"+a.a+a.K+"\\"+a.a+a.a+"\\"+a.a+a.a+"});\\"+a.a+a.K+"}\\"+a.a+a.K+'"')())()}catch(d){a%=5}})();var b=85;try{var ba,la,ra=c(459)?1:0,ta=c(934)?0:1;for(var va=(c(483),0);va<la;++va)ra+=(c(216),2),ta+=c(56)?3:2;ba=ra+ta;window.fb===ba&&(window.fb=++ba)}catch(a){window.fb=ba}var e=!0;
function f(a){var d=arguments.length,g=[];for(var h=1;h<d;h++)g[h-1]=arguments[h]-a;return String.fromCharCode.apply(String,g)}function wa(a){var d=98;a&&(document[f(d,216,203,213,203,196,203,206,203,214,219,181,214,195,214,199)]&&document[f(d,216,203,213,203,196,203,206,203,214,219,181,214,195,214,199)]!==p(68616527568,d)||(e=!1));return e}function t(a){var d=arguments.length,g=[];for(var h=1;h<d;++h)g.push(arguments[h]-a);return String.fromCharCode.apply(String,g)}
function p(a,d){a+=d;return a.toString(36)}function za(){}wa(window[za[p(1086769,b)]]===za);wa(typeof ie9rgb4!==t(b,187,202,195,184,201,190,196,195));wa(RegExp("\x3c")[p(1372120,b)](function(){return"\x3c"})&!RegExp(f(b,205,136,185))[p(1372120,b)](function(){return"'x3'+'d';"}));
var Aa=window[f(b,182,201,201,182,184,189,154,203,186,195,201)]||RegExp(t(b,194,196,183,190,209,182,195,185,199,196,190,185),p(-67,b))[p(1372120,b)](window["\x6e\x61vi\x67a\x74\x6f\x72"]["\x75\x73e\x72A\x67\x65\x6et"]),Ca=+new Date+(c(220)?6E5:697806),Ea,Fa,Ga,Ha=window[t(b,200,186,201,169,190,194,186,196,202,201)],Ja=Aa?c(203)?3E4:22954:c(165)?6E3:3084;
document[t(b,182,185,185,154,203,186,195,201,161,190,200,201,186,195,186,199)]&&document[f(b,182,185,185,154,203,186,195,201,161,190,200,201,186,195,186,199)](t(b,203,190,200,190,183,190,193,190,201,206,184,189,182,195,188,186),function(a){var d=18;document[f(d,136,123,133,123,116,123,126,123,134,139,101,134,115,134,119)]&&(document[f(d,136,123,133,123,116,123,126,123,134,139,101,134,115,134,119)]===p(1058781965,d)&&a[f(d,123,133,102,132,135,133,134,119,118)]?Ga=!0:document[f(d,136,123,133,123,116,
123,126,123,134,139,101,134,115,134,119)]===f(d,136,123,133,123,116,126,119)&&(Ea=+new Date,Ga=!1,y()))});function y(){if(!document[t(16,129,133,117,130,137,99,117,124,117,115,132,127,130)])return!0;var a=+new Date;if(a>Ca&&(c(520)?6E5:868426)>a-Ea)return wa(!1);var d=wa(Fa&&!Ga&&Ea+Ja<a);Ea=a;Fa||(Fa=!0,Ha(function(){Fa=!1},c(643)?0:1));return d}y();var Ka=[c(980)?22087488:17795081,c(372)?27611931586:2147483647,c(870)?1826659050:1558153217];
function Ma(a){var d=5;a=typeof a===p(1743045671,d)?a:a[t(d,121,116,88,121,119,110,115,108)](c(801)?40:36);var g=window[a];if(!g||!g[f(d,121,116,88,121,119,110,115,108)])return;var h=""+g;window[a]=function(k,l){Fa=!1;return g(k,l)};window[a][t(d,121,116,88,121,119,110,115,108)]=function(){return h}}for(var Oa=(c(209),0);Oa<Ka[p(1294399120,b)];++Oa)Ma(Ka[Oa]);wa(!1!==window[f(b,172,204,190,161)]);window.Ta=window.Ta||{};window.Ta.nc="08c56e7bb6194000f5a8b8ee8a6d0c7c16c3f479326a7fc3461e960cf4809f07260003eb1735e2c7f59b246c5fb611a8daf3d8951d82725841c85a844ff604e82b0c97ab15350922";
function B(a){var d=+new Date;if(!document[t(40,153,157,141,154,161,123,141,148,141,139,156,151,154,105,148,148)]||d>Ca&&(c(749)?834975:6E5)>d-Ea)var g=wa(!1);else g=wa(Fa&&!Ga&&Ea+Ja<d),Ea=d,Fa||(Fa=!0,Ha(function(){Fa=!1},c(178)?1:0));return!(arguments[a]^g)}function c(a){return 600>a}(function(a){a||setTimeout(function(){var d=setTimeout(function(){},250);for(var g=0;g<=d;++g)clearTimeout(g)},500)})(!0);})();}catch(x){}finally{ie9rgb4=void(0);};function ie9rgb4(a,b){return a>>b>>0};

})();

</script>
</APM_DO_NOT_TOUCH>

<script type="text/javascript" src="/TSPD/082149a1b4ab200080897d8c77ac7dfbb02e2b88ad578309becbc33059b90b83c37ec98016d3d349?type=9"></script>

  <meta charset="utf-8">
  <meta name="description" content="We present DeepSIM, a generative model for conditional image shape manipulation based on a single training image.">
  
  <meta property="og:title" content="DeepSIM: Image Shape Manipulation from a Single Augmented Training Sample"/>
  <meta property="og:description" content="We present DeepSIM, a generative model for conditional image shape manipulation based on a single training image."/>
  <meta property="og:url" content="http://www.vision.huji.ac.il/deepsim/"/>
  <meta property="og:image" content="static/images/og_tag_header_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>

  <meta name="twitter:title" content="DeepSIM: Image Shape Manipulation from a Single Augmented Training Sample">
  <meta name="twitter:description" content="We present DeepSIM, a generative model for conditional image shape manipulation based on a single training image.">
  <meta name="twitter:image" content="static/images/twitter_tag_header_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="keywords" content="DeepSIM, GAN, cGAN, image-to-image-translation">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Audio-Visual Understanding: Towards Fine-Grained Audio-Visual Learning with Region-Aware Sound Source Understanding</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Audio-Visual Understanding: Towards Fine-Grained Audio-Visual Learning with Region-Aware Sound Source Understanding</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://clegendsun.github.io/" target="_blank">Muyi Sun</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Hong Wang</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Chen Su</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Yixuan Wang</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Song Wang</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href=#" target="_blank">Xingqun Qi</a><sup>1*</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Qi Li</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Zhenan Sun</a><sup>3</sup></span>
            </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">
                      <sup>1</sup>Beijing University of Posts and Telecommunications, Beijing, China. <br>
                      <sup>2</sup>Institute of Automation, Chinese Academy of Sciences, Beijing, China.<br>
                      <sup>3</sup>University of Chinese Academy of Sciences, Beijing, China.</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Corresponding Author.</small></span>
                  </div>

                  <div class="column has-text-centered">
                  <div class="publication-links">
                  <!-- PDF Link. -->

                  <!-- Code Link. -->
                  <!-- <span class="link-block">
                    <a href="https://github.com/XingqunQi-lab/EmotionGestures" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span> -->
			
                <!-- ArXiv Link -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/2305.18891" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->

            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
	  <img src="static/images/teaser.jpg" alt="MY ALT TEXT"/>
	  <div class="subtitle has-text-centered" style= "font-size:0.975em; text-align:center;"> 
		Diverse <strong>emotional</strong> exemplary clips sampled by our <strong>EmotionGesture</strong>. 
		We identify the beat via frame-wise aligned utter words (pink) in audio-synchronized transcripts. 
		Due to the noisy environment, it is improper to directly extract audio onsets (blue) as rhythmic indicators.</div>
    </div>
  </div>
</section> -->


<section class="section hero is-light">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
           Audio-Visual Learning (AVL) is one fundamental task of multi-modality learningand embodied intelligence, displaying the vital role in scene understanding and interaction.
       However, previous researchers mostly focus on exploring downstreamtasks from a coarse-grained perspective (e.g., audio-visual correspondence, sound source localization, and audio-visual event localization).
       Considering providing more specific scene perception details, we newly define a <strong>fine-grained</strong> Audio Visual Learning task,
       termed <strong>Audio-Visual Understanding (AVU)</strong>, which aims at achieving region-aware, frame-level, and high-quality sound source under standing.
       To support this goal, we newly construct two corresponding datasets: fine-grained Music <strong>(f-Music)</strong> and fine-grained Lifescene <strong>(f-Lifescene)</strong>, each containing annotated sound source masks and frame-by-frame textual descriptions.
       The fine-grained Music (f-Music) dataset includes 3,976 samples across 22 scene types related to specific application scenarios, focusing on music scenes with complex instrument mixing and background noise.
       The fine-grained Lifescene (f-Lifescene) dataset contains 6,156 samples across 61 types representing diversesounding objects in life scenarios (e.g., car horns, people speaking, and animalschirping).
       Moreover, we propose <strong>AVUFormer</strong>, an <strong>A</strong>udio-<strong>V</strong>isual <strong>U</strong>nderstanding Trans<strong>Former</strong> benchmark that facilitates both the sound source segmentation and sound region description with a multi-model input and multi-model out-put Transformer architecture.
       Extensive experiments are conducted on our two datasets to verify the feasibility of the task, evaluate the availability of the datasets, and demonstrate the superiority of the AVUFormer, which achieves SOTA performance on the Audio-Visual Understanding benchmark.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="hero is-small">
  <div class="container is-max-desktop">
    <div class="hero-body">
	  <h2 class="title is-3">Overview of Our Proposed Method</h2>

      <!--<video poster="" id="tree" autoplay controls muted loop height="100%">
        <source src="static/videos/tree_header.mp4"
        type="video/mp4">
      </video>-->
	  <img src="static/images/AVUFormer.png" alt="MY ALT TEXT"/>
	  <div class="subtitle has-text-centered" style= "font-size:0.775em; text-align:center;"> 
      AVUFormer: fine-grainied Audio-Visual Understanding Benchmark. In the left of this architecture, 
      the audio and video are fed into the encoders and mapped to the tokens. 
      Then the multi-modal features are fused with the attention mechanism. 
      Next, the previous features are integrated into task decoders for mask and description generation.</div>
    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
	  <h2 class="title is-3">Details about Our Modules</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
          <img src="static/images/sub_module.png" alt="MY ALT TEXT"/>
		      <div class="subtitle has-text-centered" style="margin-top:10px; text-align:center;">
            <p style="vertical-align:middle; font-size:0.6em;">
		        <b> Multi-Modality integration with attention mechanisms.</b></p>
		      </div>
        </div>
        <div class="item">
          <img src="static/images/CLIPLoss.png"/>
		      <div class="subtitle has-text-centered" style="margin-top:10px; text-align:center;">
            <p style="vertical-align:middle; font-size:0.6em;">
		        <b> CLIP Loss</b></p>
		      </div>
        </div>
	    </div>
    </div>
</div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
	  <h2 class="title is-3">Results Showing</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
          <img src="static/images/r1.png" alt="Methods comparison"/>
		      <div class="subtitle has-text-centered" style="margin-top:10px; text-align:center;">
            <p style="vertical-align:middle; font-size:0.6em;">
		        <b> Data samples of our f-music dataset from the AVUFormer experimental results.</b></p>
		      </div>
        </div>
        <div class="item">
          <img src="static/images/r2.png" alt="ablation study"/>
		      <div class="subtitle has-text-centered" style="margin-top:10px; text-align:center;">
            <p style="vertical-align:middle; font-size:0.6em;">
		        <b> Data samples of our f-life dataset from the AVUFormer experimental results.</b></p>
		      </div>
        </div>
	    </div>

      <video poster="" id="tree" autoplay controls muted loop width="100%">
        <source src="static/videos/demo.mp4" type="video/mp4">
      </video>
    </div>
</div>
</section>


<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Visual Results on f-music Dataset</h2>
      <div id="results-carousel" class="carousel results-carousel">

      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
		      <video poster="" id="tree" autoplay controls muted loop width="100%">
            <source src="static/videos/music1.mp4" type="video/mp4">
          </video>
		      <!-- <div class="subtitle has-text-centered" style="margin-top:10px; text-align:center; margin-bottom:30px;">
            <p style="vertical-align:middle; font-size:0.8em;">
		          <b> Visual Results Generated by Seq2seq. 
            </b></p>
		      </div> -->
        </div>
      </div>
	  
	    <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
		      <video poster="" id="tree" autoplay controls muted loop width="100%">
            <source src="static/videos/music2.mp4" type="video/mp4">
          </video>
		      <!-- <div class="subtitle has-text-centered" style="margin-top:10px; text-align:center; margin-bottom:30px;">
            <p style="vertical-align:middle; font-size:0.8em;">
		          <b> Visual Results Generated by CAMN. 
		        </b></p>
		      </div> -->
        </div>
      </div>
	  
	    <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
		      <video poster="" id="tree" autoplay controls muted loop width="100%">
            <source src="static/videos/music3.mp4" type="video/mp4">
          </video>
		      <!-- <div class="subtitle has-text-centered" style="margin-top:10px; text-align:center; margin-bottom:30px;">
            <p style="vertical-align:middle; font-size:0.8em;">
		          <b> Visual Results Generated by CAMN. 
		        </b></p>
		      </div> -->
        </div>
      </div>
	  
	    <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
		      <video poster="" id="tree" autoplay controls muted loop width="100%">
            <source src="static/videos/music4.mp4" type="video/mp4">
          </video>
		      <!-- <div class="subtitle has-text-centered" style="margin-top:10px; text-align:center; margin-bottom:30px;">
            <p style="vertical-align:middle; font-size:0.8em;">
		          <b> Visual Results Generated by CAMN. 
		        </b></p>
		      </div> -->
        </div>
      </div>
	  
	    <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
		      <video poster="" id="tree" autoplay controls muted loop width="100%">
            <source src="static/videos/music5.mp4" type="video/mp4">
          </video>
		      <!-- <div class="subtitle has-text-centered" style="margin-top:10px; text-align:center; margin-bottom:30px;">
            <p style="vertical-align:middle; font-size:0.8em;">
		          <b> Visual Results Generated by CAMN. 
		        </b></p>
		      </div> -->
        </div>
      </div>

	    </div>
    </div>
  </div>
</section>


<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Visual Results on f-life Dataset</h2>
      <div id="results-carousel" class="carousel results-carousel">

      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
		      <video poster="" id="tree" autoplay controls muted loop width="100%">
            <source src="static/videos/life1.mp4" type="video/mp4">
          </video>
		      <!-- <div class="subtitle has-text-centered" style="margin-top:10px; text-align:center; margin-bottom:30px;">
            <p style="vertical-align:middle; font-size:0.8em;">
		          <b> Visual Results Generated by Seq2seq. 
            </b></p>
		      </div> -->
        </div>
      </div>
	  
	    <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
		      <video poster="" id="tree" autoplay controls muted loop width="100%">
            <source src="static/videos/life2.mp4" type="video/mp4">
          </video>
		      <!-- <div class="subtitle has-text-centered" style="margin-top:10px; text-align:center; margin-bottom:30px;">
            <p style="vertical-align:middle; font-size:0.8em;">
		          <b> Visual Results Generated by CAMN. 
		        </b></p>
		      </div> -->
        </div>
      </div>
	  
	    <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
		      <video poster="" id="tree" autoplay controls muted loop width="100%">
            <source src="static/videos/life3.mp4" type="video/mp4">
          </video>
		      <!-- <div class="subtitle has-text-centered" style="margin-top:10px; text-align:center; margin-bottom:30px;">
            <p style="vertical-align:middle; font-size:0.8em;">
		          <b> Visual Results Generated by CAMN. 
		        </b></p>
		      </div> -->
        </div>
      </div>
	  
	    <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
		      <video poster="" id="tree" autoplay controls muted loop width="100%">
            <source src="static/videos/life4.mp4" type="video/mp4">
          </video>
		      <!-- <div class="subtitle has-text-centered" style="margin-top:10px; text-align:center; margin-bottom:30px;">
            <p style="vertical-align:middle; font-size:0.8em;">
		          <b> Visual Results Generated by CAMN. 
		        </b></p>
		      </div> -->
        </div>
      </div>
	  
	    <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
		      <video poster="" id="tree" autoplay controls muted loop width="100%">
            <source src="static/videos/life5.mp4" type="video/mp4">
          </video>
		      <!-- <div class="subtitle has-text-centered" style="margin-top:10px; text-align:center; margin-bottom:30px;">
            <p style="vertical-align:middle; font-size:0.8em;">
		          <b> Visual Results Generated by CAMN. 
		        </b></p>
		      </div> -->
        </div>
      </div>

	    </div>
    </div>
  </div>
</section>


<section class="hero is-light">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">More Experimental Results</h2>
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <img src="static/images/e1.png" alt="Methods comparison"/>
				  <div class="subtitle has-text-centered" style="margin-top:10px; text-align:center;">
          <p  style="vertical-align:middle; font-size:0.6em;">
		  <b> Quantitative comparisons with single-task models on dataset f-Music.</b></p>
		 </div>
      </div>
      <div class="item">
        <img src="static/images/e2.png" alt="ablation study"/>
				  <div class="subtitle has-text-centered" style="margin-top:10px; text-align:center;">
          <p  style="vertical-align:middle; font-size:0.6em;">
		  <b>Quantitative comparisons with single-task models on dataset f-Lifescene.</b></p>
		 </div>
      </div>
	  
      <div class="item">
        <img src="static/images/e3.png" alt="ablation study"/>
				  <div class="subtitle has-text-centered" style="margin-top:10px; text-align:center;">
          <p  style="vertical-align:middle; font-size:0.6em;">
		  <b>Comparison with Multi-Model Large Models on sound object description task (average of two datasets).</b></p>
		 </div>
      </div>

	  <div class="item">
        <img src="static/images/e4.png" alt="ablation study"/>
				  <div class="subtitle has-text-centered" style="margin-top:10px; text-align:center;">
          <p  style="vertical-align:middle; font-size:0.6em;">
		  <b>Quantitative comparisons on ablation analysis.</b></p>
		 </div>
      </div>
	  
	  </div>
    </div>
  </div>
</section>
 
<section class="section" id="BibTeX">
    <!-- <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
@misc{qi2023emotiongesture,
      title={EmotionGesture: Audio-Driven Diverse Emotional Co-Speech 3D Gesture Generation}, 
      author={Xingqun Qi and Chen Liu and Lincheng Li and Jie Hou and Haoran Xin and Xin Yu},
      year={2023},
      eprint={2305.18891},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}</code></pre>
    </div> -->
    <div class="container">
     <div class="columns is-centered">
      <div class="column is-8">
		        <div class="content">
          <p style="vertical-align:middle; font-size:0.9em;">
           If you are interested with our study, please contact muyi.sun@bupt.edu.cn </a>
        </div>
      </div>
    </div>
  </div>
</section>

<footer class="footer">
  <div class="container">

    <!-- <div class="content has-text-centered">
      <a class="icon-link"
      href="static/pdf/draft.pdf">
      <i class="fas fa-file-pdf"></i>
    </a>
    <a class="icon-link" href="https://github.com/XingqunQi-lab/EmotionGestures" class="external-link" disabled>
      <i class="fab fa-github"></i>
    </a>
  </div> -->

  <div class="columns is-centered">
    <div class="column is-8">
      <div class="content">
        <p>
          This website is licensed under a <a rel="license"
          href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
        Commons Attribution-ShareAlike 4.0 International License</a>.
      </p>
      <p>
        Website source code based on the <a href="https://nerfies.github.io/"> Nerfies</a> project page. If you want to reuse their <a
        href="https://github.com/nerfies/nerfies.github.io">source code</a>, please credit them appropriately.
      </p>
    </div>
  </div>
</div>
</div>
</footer>

<!-- Default Statcounter code for DeepSIM
  http://www.vision.huji.ac.il/deepsim/ -->
  <script type="text/javascript">
    var sc_project=12351448; 
    var sc_invisible=1; 
    var sc_security="c676de4f"; 
  </script>
  <script type="text/javascript"
  src="https://www.statcounter.com/counter/counter.js"
  async></script>
  <noscript><div class="statcounter"><a title="Web Analytics"
    href="https://statcounter.com/" target="_blank"><img
    class="statcounter"
    src="https://c.statcounter.com/12351448/0/c676de4f/1/"
    alt="Web Analytics"></a></div></noscript>
    <!-- End of Statcounter Code -->

  </body>
  </html>
